# Profiling



## ğŸ”§ Action Planï¼ˆThree Phasesï¼‰
### Phase 1ï¸âƒ£: Multi-Device Log Redirection Configuration
#### Background
By default, kernel logs from all 8 XPU devices are interleaved and emitted to [stdout], resulting in:
- It becomes impossible to distinguish which log originates from which device.
- Timestamps become interleaved, making it difficult to analyze the temporal relationships.
- Single-device bottlenecks are masked by global aggregation.

#### Solution
During model initialization, create separate log files for each device.
#### Code Explanation (embedded in qwen2.py)
```python
import os  # â† Ensure this is imported at the top of the file
from vllm.distributed import get_tensor_model_parallel_rank  # â† Import function to get the tensor model parallel rank

class Qwen2Model(nn.Module):

    def __init__(self,
                 *,
                 vllm_config: VllmConfig,
                 prefix: str = "",
                 decoder_layer_type: type[nn.Module] = Qwen2DecoderLayer):
        super().__init__()

        # ========== [Expert Solution] Kunlun XPU Multi-Device Log Redirection ==========
        try:
            # Step 1: Get the current XPU device's rank (0~7)
            rank = get_tensor_model_parallel_rank()
            
            # Step 2: Create log directory (works with your get_kernel_time_ex.py)
            log_dir = "./xpu_logs"
            os.makedirs(log_dir, exist_ok=True)
            
            # Step 3: Generate a separate log file for each device
            log_file = os.path.join(log_dir, f"rank_{rank}.log")
            
            # Step 4: Core operation â€“ redirect file descriptors
            # os.O_TRUNC: Clear previous logs on each run to avoid mixing outputs
            fd = os.open(log_file, os.O_WRONLY | os.O_CREAT | os.O_TRUNC, 0o664)
            os.dup2(fd, 1)  # Redirect stdout â†’ rank_X.log
            os.dup2(fd, 2)  # Redirect stderr â†’ rank_X.log
            os.close(fd)     # Close original file descriptor; redirection persists
            
            # Optional: print a confirmation message (will go into rank_X.log)
            print(f"[Qwen2Model Init] Rank {rank} log redirected to {log_file}")
            
        except Exception as e:
            # Fallback mechanism: failure to redirect logs does not affect model loading
            print(f"[WARNING] Failed to redirect log for rank: {e}", flush=True)
        # ========== End of log redirection code ==========

```
#### âš ï¸ Common Issues
**Q1**:Why not use Python's `logging` module?
**A**:The XPU runtime kernel logs are emitted from the C++ layer and cannot be captured by Pythonâ€™s `logging` module. Redirection via low-level file descriptors is required.
**Q1**:Will logs be lost if the model fails to load??
**A**:The `try-except` block ensures that if log redirection fails, it falls back to the default behavior without affecting model startup.

### Phase 2ï¸âƒ£: Profiling Environment Activation
#### ğŸš€ vLLM Launch
```bash
unsetÂ XPU_DUMMY_EVENT
exportÂ XPU_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
exportÂ XPU_USE_MOE_SORTED_THRES=1
exportÂ XFT_USE_FAST_SWIGLU=1
exportÂ XMLIR_CUDNN_ENABLED=1
exportÂ XPU_USE_DEFAULT_CTX=1
exportÂ XMLIR_FORCE_USE_XPU_GRAPH=1
exportÂ XPU_USE_FAST_SWIGLU=1
exportÂ VLLM_HOST_IP=$(hostnameÂ -i)
echoÂ "VLLM_HOST_IP:Â $VLLM_HOST_IP"

exportÂ XMLIR_ENABLE_MOCK_TORCH_COMPILE=false

export XPUAPI_DEBUG=0x1              # Enable kernel performance logging
export XPURT_DISPATCH_MODE=PROFILING # Activate profiling mode

USE_ORI_ROPE=1Â VLLM_USE_V1=1Â pythonÂ -mÂ vllm.entrypoints.openai.api_serverÂ \
Â Â Â Â Â Â --hostÂ 0.0.0.0Â \
Â Â Â Â Â Â --portÂ 8000Â \
Â Â Â Â Â Â --modelÂ /models/Qwen2.5-72B-InstructÂ \
Â Â Â Â Â Â --gpu-memory-utilizationÂ 0.9Â \
Â Â Â Â Â Â --trust-remote-codeÂ \
Â Â Â Â Â Â --max-model-lenÂ 32768Â \
Â Â Â Â Â Â --tensor-parallel-sizeÂ 8Â \
Â Â Â Â Â Â --dtypeÂ float16Â \
Â Â Â Â Â Â --max_num_seqsÂ 512Â \
Â Â Â Â Â Â --max_num_batched_tokensÂ 32768Â \
Â Â Â Â Â Â --max-seq-len-to-captureÂ 32768Â \
Â Â Â Â Â Â --block-sizeÂ 128Â \
Â Â Â Â Â Â --no-enable-prefix-cachingÂ \
Â Â Â Â Â Â --no-enable-chunked-prefillÂ \
Â Â Â Â Â Â --distributed-executor-backendÂ mpÂ \
Â Â Â Â Â Â --served-model-nameÂ Qwen2.5-72B-InstructÂ \
Â Â Â Â Â Â --compilation-config '{"splitting_ops": ["vllm.unified_attention_with_output_kunlun",
            "vllm.unified_attention", "vllm.unified_attention_with_output",
            "vllm.mamba_mixer2"]}' 2>&1 | tee output_p800.log

```


#### ğŸš€ Client Load Testing
```bash
#!/bin/bash

# Define test combinations array (concurrency x input length x output length)
TEST_COMBINATIONS=(
    "8x1024x1024" # Medium-low concurrency
)

# Create result directory
RESULT_DIR="bench_$(date +%Y%m%d_%H%M)"
mkdir -p $RESULT_DIR

# Summary results file
SUMMARY_FILE="$RESULT_DIR/summary_results.csv"
echo "num_prompts,input_len,output_len,throughput,latency_mean,latency_p50,latency_p90,latency_p99" >$SUMMARY_FILE

# Progress counter
TOTAL_TESTS=${#TEST_COMBINATIONS[@]}
CURRENT_TEST=0

# Loop through different test combinations
for COMBINATION in "${TEST_COMBINATIONS[@]}"; do
    # Parse combination parameters
    NUM_PROMPTS=$(echo $COMBINATION | cut -d'x' -f1)
    INPUT_LEN=$(echo $COMBINATION | cut -d'x' -f2)
    OUTPUT_LEN=$(echo $COMBINATION | cut -d'x' -f3)

    # Update progress
    CURRENT_TEST=$((CURRENT_TEST + 1))

    echo "=========================================================="
    echo "Test progress: $CURRENT_TEST/$TOTAL_TESTS ($(printf "%.1f" $(echo "$CURRENT_TEST/$TOTAL_TESTS*100" | bc -l))%)"
    echo "Current test configuration: concurrency=$NUM_PROMPTS, input length=$INPUT_LEN, output length=$OUTPUT_LEN"
    echo "=========================================================="

    OUTPUT_FILE="$RESULT_DIR/p800_${NUM_PROMPTS}_${INPUT_LEN}_${OUTPUT_LEN}.log"

    # Run benchmark
    python3 -m vllm.entrypoints.cli.main bench serve \
        --host 127.0.0.1 \
        --port 8000 \
        --backend vllm \
        --model Qwen2.5-72B-Instruct \
        --dataset-name random \
        --num-prompts $NUM_PROMPTS \
        --random-input-len $INPUT_LEN \
        --random-output-len $OUTPUT_LEN \
        --tokenizer /ssd1/models/Qwen2.5-72B-Instruct \
        --ignore-eos 2>&1 | tee $OUTPUT_FILE

    # Wait 15 seconds to let the service recover
    echo "Waiting 15 seconds before the next round..."
    sleep 15

    # Extract key performance metrics from output and append to summary file
    THROUGHPUT=$(grep "Throughput" $OUTPUT_FILE | awk '{print $2}')
    LATENCY_MEAN=$(grep "Mean latency" $OUTPUT_FILE | awk '{print $3}')
    LATENCY_P50=$(grep "p50 latency" $OUTPUT_FILE | awk '{print $3}')
    LATENCY_P90=$(grep "p90 latency" $OUTPUT_FILE | awk '{print $3}')
    LATENCY_P99=$(grep "p99 latency" $OUTPUT_FILE | awk '{print $3}')

    echo "$NUM_PROMPTS,$INPUT_LEN,$OUTPUT_LEN,$THROUGHPUT,$LATENCY_MEAN,$LATENCY_P50,$LATENCY_P90,$LATENCY_P99" >>$SUMMARY_FILE
done

# Output summary report
echo "=========================================================="
echo "Benchmark completed! Results saved in: $RESULT_DIR"
echo "=========================================================="


```

### Phase 3ï¸âƒ£: Log Analysis and Bottleneck Identification
```text
xpu_logs/
â”œâ”€ rank_0.log
â”œâ”€ rank_1.log
â”œâ”€ rank_2.log
â”œâ”€ rank_3.log
â”œâ”€ rank_4.log
â”œâ”€ rank_5.log
â”œâ”€ rank_6.log
â””â”€ rank_7.log

```
#### ğŸ” Script Workflow (op_log.py)
**Input**:Raw Kernel Logs (Sample Format)
```
[XPURT_PROF] void xblas_xpu3::fc_cdnn_infer<float16,...> 123456 ns
[XPURT_PROF] void kl3_all_reduce<float16> 987654 ns
```
**Processing logic**
:::::{tab-set}
::::{tab-item} op_log.py 


```python
"""
AÂ betterÂ versionÂ ofÂ 'get_op_time.py',Â getÂ moreÂ levelÂ dumpÂ andÂ supportÂ kl3.
Â 
Usage:Â python3Â get_kernel_time_ex.pyÂ --help
"""
Â 
importÂ os
importÂ sys
importÂ re
Â 
unit_factorsÂ =Â [0.9,Â 1.3,Â 1.45]Â #Â kunlun1,Â kunlun2,Â kunlun3
patternsÂ =Â ["\[XPURT_PROF\]Â (\S+)\s+\S+\s+(\S+)Â ns",Â "\[XPURT_PROF\]Â (\S+)\s+(\S+)\s+\S+Â ns"]
tab_space_numÂ =Â int(4)
Â 
defÂ get_total_time(res):
Â Â Â Â total_timeÂ =Â 0.0
Â Â Â Â forÂ iÂ inÂ res.values():
Â Â Â Â Â Â Â Â total_timeÂ +=Â i
Â Â Â Â returnÂ Â total_time
Â 
defÂ print_info_op(res,Â cnt,Â unit,Â op):
Â Â Â Â total_timeÂ =Â get_total_time(res)
Â Â Â Â total_cntÂ =Â 0
Â Â Â Â #Â printÂ detailedÂ opÂ time
Â Â Â Â lis=sorted(res.items(),Â key=lambdaÂ d:d[1],Â reverse=True)
Â Â Â Â ifÂ sys.version_info.majorÂ ==Â 2:
Â Â Â Â Â Â Â Â importÂ commands
Â Â Â Â Â Â Â Â forÂ iÂ inÂ range(len(lis)):
Â Â Â Â Â Â Â Â Â Â Â Â (status,Â cmd_output)Â =Â commands.getstatusoutput("c++filtÂ {}".format(lis[i][0]))
Â Â Â Â Â Â Â Â Â Â Â Â ifÂ statusÂ ==Â 0:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â formt_typeÂ =Â (cmd_output.split('('))[0]
Â Â Â Â Â Â Â Â Â Â Â Â total_cntÂ +=Â cnt[lis[i][0]]
Â Â Â Â elifÂ sys.version_info.majorÂ ==Â 3:
Â Â Â Â Â Â Â Â importÂ subprocess
Â Â Â Â Â Â Â Â forÂ iÂ inÂ range(len(lis)):
Â Â Â Â Â Â Â Â Â Â Â Â (status,Â cmd_output)Â =Â subprocess.getstatusoutput("c++filtÂ {}".format(lis[i][0]))
Â Â Â Â Â Â Â Â Â Â Â Â ifÂ statusÂ ==Â 0:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â formt_typeÂ =Â (cmd_output.split('('))[0]
Â Â Â Â Â Â Â Â Â Â Â Â total_cntÂ +=Â cnt[lis[i][0]]
Â Â Â Â print(f"{op}Â {total_timeÂ /Â unit}Â {total_cnt}")
Â 
defÂ print_info_kernel(res,Â cnt,Â unit):
Â Â Â Â total_timeÂ =Â get_total_time(res)
Â Â Â Â total_cntÂ =Â 0
Â Â Â Â print("TotalÂ time(ms)Â isÂ {}".format(total_timeÂ /Â unit))
Â Â Â Â #Â printÂ detailedÂ opÂ time
Â Â Â Â lis=sorted(res.items(),Â key=lambdaÂ d:d[1],Â reverse=True)
Â Â Â Â ifÂ sys.version_info.majorÂ ==Â 2:
Â Â Â Â Â Â Â Â print("{:<90}{:<10}{:<15}{:<15}".format("OpÂ type",Â "count",Â "time(ms)",Â "%"))
Â Â Â Â Â Â Â Â importÂ commands
Â Â Â Â Â Â Â Â forÂ iÂ inÂ range(len(lis)):
Â Â Â Â Â Â Â Â Â Â Â Â (status,Â cmd_output)Â =Â commands.getstatusoutput("c++filtÂ {}".format(lis[i][0]))
Â Â Â Â Â Â Â Â Â Â Â Â ifÂ statusÂ ==Â 0:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â formt_typeÂ =Â (cmd_output.split('('))[0]
Â Â Â Â Â Â Â Â Â Â Â Â print("{:<90}{:<10}{:<15}{:<15.5}".format(formt_type,Â cnt[lis[i][0]],Â lis[i][1]Â /Â unit,Â \
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â lis[i][1]Â /Â total_timeÂ *Â 100))
Â Â Â Â Â Â Â Â Â Â Â Â total_cntÂ +=Â cnt[lis[i][0]]
Â Â Â Â elifÂ sys.version_info.majorÂ ==Â 3:
Â Â Â Â Â Â Â Â print("{:<90}{:<10}{:<20}{:<20}".format("OpÂ type",Â "count",Â "time(ms)",Â "%"))
Â Â Â Â Â Â Â Â importÂ subprocess
Â Â Â Â Â Â Â Â forÂ iÂ inÂ range(len(lis)):
Â Â Â Â Â Â Â Â Â Â Â Â (status,Â cmd_output)Â =Â subprocess.getstatusoutput("c++filtÂ {}".format(lis[i][0]))
Â Â Â Â Â Â Â Â Â Â Â Â ifÂ statusÂ ==Â 0:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â formt_typeÂ =Â (cmd_output.split('('))[0]
Â Â Â Â Â Â Â Â Â Â Â Â print("{:<150}{:<10}{:<25}{:<20.5}".format(formt_type,Â cnt[lis[i][0]],Â lis[i][1]Â /Â unit,Â \
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â lis[i][1]Â /Â total_timeÂ *Â 100))
Â Â Â Â Â Â Â Â Â Â Â Â total_cntÂ +=Â cnt[lis[i][0]]
Â 
Â Â Â Â print("TotalÂ countÂ isÂ {}".format(total_cnt))
Â 
defÂ count_head_spaces(s:Â str)Â ->Â int:
Â Â Â 
Â Â Â Â countÂ =Â 0
Â Â Â Â forÂ charÂ inÂ s:
Â Â Â Â Â Â Â Â ifÂ charÂ ==Â 'Â ':
Â Â Â Â Â Â Â Â Â Â Â Â countÂ +=Â 1
Â Â Â Â Â Â Â Â else:
Â Â Â Â Â Â Â Â Â Â Â Â break
Â Â Â Â returnÂ count
Â 
defÂ process_line(lines,Â pattern1,Â unit_factor,Â dump_level):
Â Â Â Â """Â processÂ aÂ lineÂ inÂ aÂ fileÂ withÂ profilingÂ info
Â 
Â Â Â Â Args:
Â Â Â Â Â Â Â Â unit_factor:Â AÂ factorÂ differentiatedÂ byÂ KUNLUN1Â andÂ KUNLUN2
Â 
Â Â Â Â """
Â Â Â Â resÂ =Â {}
Â Â Â Â cntÂ =Â {}
Â Â Â Â opÂ =Â "init_op"
Â Â Â Â unitÂ =Â unit_factorÂ *Â 1000Â *Â 1000Â #Â nsÂ ->Â ms
Â Â Â Â wait_next_oneÂ =Â False
Â Â Â Â forÂ iÂ inÂ range(len(lines)):
Â Â Â Â Â Â Â Â cur_lineÂ =Â lines[i]
Â Â Â Â Â Â Â Â ifÂ "gtest_"Â inÂ cur_line:
Â Â Â Â Â Â Â Â Â Â Â Â cur_levelÂ =Â count_head_spaces(cur_line)Â /Â tab_space_num
Â Â Â Â Â Â Â Â Â Â Â Â ifÂ cur_levelÂ ==Â dump_level:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â wait_next_oneÂ =Â False
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print_info_op(res,Â cnt,Â unit,Â op)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â clearÂ buf
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â resÂ =Â {}
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â cntÂ =Â {}
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â opÂ =Â cur_line.lstrip().rstrip()
Â Â Â Â Â Â Â Â Â Â Â Â elifÂ cur_levelÂ <Â dump_level:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â wait_next_oneÂ =Â True
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â skipÂ recordÂ kernelÂ timeÂ untimeÂ nextÂ one
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â continue
Â Â Â Â Â Â Â Â ifÂ wait_next_one:
Â Â Â Â Â Â Â Â Â Â Â Â #Â skipÂ recordÂ kernelÂ time
Â Â Â Â Â Â Â Â Â Â Â Â continue
Â Â Â Â Â Â Â Â matchÂ =Â re.match(pattern1,Â lines[i])
Â Â Â Â Â Â Â Â ifÂ match:
Â Â Â Â Â Â Â Â Â Â Â Â op_typeÂ =Â match.group(1)
Â Â Â Â Â Â Â Â Â Â Â Â op_timeÂ =Â match.group(2)
Â Â Â Â Â Â Â Â Â Â Â Â ifÂ op_typeÂ inÂ res:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â res[op_type]Â +=Â float(op_time)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â cnt[op_type]Â +=Â 1
Â Â Â Â Â Â Â Â Â Â Â Â else:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â res[op_type]Â =Â float(op_time)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â cnt[op_type]Â =Â 1
Â 
Â Â Â Â #Â getÂ leftÂ totalÂ time
Â Â Â Â ifÂ dump_levelÂ ==Â -1:
Â Â Â Â Â Â Â Â print_info_kernel(res,Â cnt,Â unit)
Â Â Â Â else:
Â Â Â Â Â Â Â Â print_info_op(res,Â cnt,Â unit,Â op)
Â Â Â Â returnÂ res
Â 
defÂ process_file(file_name,Â pattern2,Â unit_factor,Â dump_levelÂ =Â -1):
Â Â Â Â """Â ProcessÂ aÂ fileÂ lineÂ byÂ line
Â 
Â Â Â Â IterativelyÂ processÂ eachÂ lineÂ inÂ theÂ targetÂ file.
Â 
Â Â Â Â """
Â 
Â Â Â Â withÂ open(file_name,Â "r")Â asÂ f:
Â Â Â Â Â Â Â Â linesÂ =Â f.readlines()
Â Â Â Â Â Â Â Â f1_res_listÂ =Â process_line(lines,Â pattern2,Â unit_factor,Â dump_level)
Â 
ifÂ __name__Â ==Â '__main__':
Â Â Â Â importÂ argparse
Â 

Â Â Â Â parserÂ =Â argparse.ArgumentParser()
Â 

Â Â Â Â groupÂ =Â parser.add_mutually_exclusive_group()
Â Â Â Â group.add_argument('-xpu1',Â action='store_true',Â help='æŒ‡å®šä¸ºÂ xpu1')
Â Â Â Â group.add_argument('-xpu2',Â action='store_true',Â help='æŒ‡å®šä¸ºÂ xpu2')
Â Â Â Â group.add_argument('-xpu3',Â action='store_true',Â help='æŒ‡å®šä¸ºÂ xpu3')
Â Â Â Â parser.add_argument('--level',Â type=int,Â default=-1,Â help='æŒ‡å®šÂ dumpÂ ç¼©è¿›çº§åˆ«ï¼ˆé»˜è®¤ä¸ºÂ -1ï¼‰')

Â Â Â Â parser.add_argument('filename',Â help='è¦å¤„ç†çš„æ–‡ä»¶å')
Â 

Â Â Â Â argsÂ =Â parser.parse_args()
Â 

Â Â Â Â filenameÂ =Â args.filename
Â Â Â Â xpu_versionÂ =Â 0
Â Â Â Â ifÂ args.xpu2:
Â Â Â Â Â Â Â Â xpu_versionÂ =Â 1
Â Â Â Â ifÂ args.xpu3:
Â Â Â Â Â Â Â Â xpu_versionÂ =Â 2
Â Â Â Â dump_levelÂ =Â args.level
Â Â Â Â print(f'Filename:Â {filename}')
Â Â Â Â print(f'-xpuÂ option:Â {xpu_version}')
Â Â Â Â print(f'--levelÂ option:Â {dump_level}')
Â 
Â Â Â Â unit_factorÂ =Â unit_factors[xpu_version]
Â Â Â Â pattern_idxÂ =Â 0
Â Â Â Â ifÂ xpu_versionÂ >Â 0:
Â Â Â Â Â Â Â Â pattern_idxÂ =Â 1
Â Â Â Â process_file(filename,Â patterns[pattern_idx],Â unit_factor,Â dump_level)
Â 
```

::::

::::{tab-item} op_log.sh



```bash

forÂ iÂ inÂ {0..7};Â do
Â Â Â Â pythonÂ op_log.pyÂ -xpu3Â xpu_logs/rank_${i}.logÂ >Â analysis_rank${i}.log
Â Â Â Â echoÂ "RankÂ ${i}Â åˆ†æå®Œæˆ"
done


forÂ iÂ inÂ {0..7};Â do
Â Â Â Â echoÂ "===Â RankÂ $iÂ ==="Â 
Â Â Â Â headÂ -nÂ 6Â analysis_rank${i}.logÂ |Â tailÂ -nÂ 5
done
```
::::
:::::
#### ğŸ“ˆ Output Example (analysis_rank0.log)
```
Filename:Â xpu_logs/rank_0.log
-xpuÂ option:Â 2
--levelÂ option:Â -1
TotalÂ time(ms)Â isÂ 53742.29571862069
OpÂ typeÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â countÂ Â Â Â Â time(ms)Â Â Â Â Â Â Â Â Â Â Â Â %Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 
voidÂ xblas_xpu3::fc_cdnn_infer<float16,Â float16,Â float16,Â float16,Â float,Â float,Â float,Â float,Â 1>Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 661569Â Â Â Â 22736.262780689656Â Â Â Â Â Â Â 42.306Â Â Â Â Â Â Â Â Â Â Â Â Â Â 
voidÂ kl3_all_reduce<float16>Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 176134Â Â Â Â 14782.525712413793Â Â Â Â Â Â Â 27.506Â Â Â Â Â Â Â Â Â Â Â Â Â Â 
voidÂ kl3_all_reduce_butterfly<float16>Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 164864Â Â Â Â 4197.28395862069Â Â Â Â Â Â Â Â Â 7.81Â Â Â Â Â Â Â Â Â Â Â 
```
#### ğŸš¨ Troubleshooting Guide
|Symptom|Cause|Solution|
|-|-|-|
|`xpu_logs` directory is empty|XPUAPI_DEBUG not enabled|Verify that the environment variable is correctly set|
All 8 log files have identical content|Multi-process backend not activated|Ensure `--distributed-executor-backend` mp is specified|
|Throughput drops >15%|Profiling overhead too high|Enable profiling only during analysis; disable in production|
